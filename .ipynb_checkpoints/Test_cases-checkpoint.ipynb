{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b5f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "import io\n",
    "import multiprocessing as mp\n",
    "import urllib\n",
    "from urllib.request import Request, urlopen\n",
    "from pyresparser import ResumeParser\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323a2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remote_data():\n",
    "    try:\n",
    "        remote_file = 'https://www.omkarpathak.in/downloads/OmkarResume.pdf'\n",
    "        print('Extracting data from: {}'.format(remote_file))\n",
    "        req = Request(remote_file, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req).read()\n",
    "        _file = io.BytesIO(webpage)\n",
    "        _file.name = remote_file.split('/')[-1]\n",
    "        resume_parser = ResumeParser(_file)\n",
    "        print(resume_parser)\n",
    "        return [resume_parser.get_extracted_data()]\n",
    "    except urllib.error.HTTPError:\n",
    "        return 'File not found. Please provide correct URL for resume file.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2923049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from: https://www.omkarpathak.in/downloads/OmkarResume.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmazhar\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v3.2 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyresparser.resume_parser.ResumeParser object at 0x0000011BF2EE8100>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'Omkar Pathak',\n",
       "  'email': 'omkarpathak27@gmail.com',\n",
       "  'mobile_number': '8087996634',\n",
       "  'skills': ['Unix',\n",
       "   'Analytics',\n",
       "   'Security',\n",
       "   'Flask',\n",
       "   'Auditing',\n",
       "   'Rest',\n",
       "   'Postgresql',\n",
       "   'Php',\n",
       "   'Cloud',\n",
       "   'Django',\n",
       "   'Html',\n",
       "   'Architecture',\n",
       "   'Css',\n",
       "   'Windows',\n",
       "   'Mysql',\n",
       "   'Photography',\n",
       "   'C++',\n",
       "   'Parser',\n",
       "   'Apis',\n",
       "   'Api',\n",
       "   'C',\n",
       "   'Technical',\n",
       "   'Hadoop',\n",
       "   'Algorithms',\n",
       "   'Docker',\n",
       "   'Linux',\n",
       "   'Programming',\n",
       "   'Celery',\n",
       "   'Automation',\n",
       "   'Python',\n",
       "   'Javascript',\n",
       "   'Scrum',\n",
       "   'Github',\n",
       "   'Operating systems',\n",
       "   'Shell',\n",
       "   'Migration',\n",
       "   'Engineering',\n",
       "   'Writing'],\n",
       "  'college_name': None,\n",
       "  'degree': ['B.E. IN COMPUTER ENGINEERING'],\n",
       "  'designation': ['Schlumberger\\nDATA ENGINEER'],\n",
       "  'experience': ['Schlumberger',\n",
       "   'DATA ENGINEER',\n",
       "   '• Developed and managed custom containerized data ingestion framework using Nifi',\n",
       "   '• Author and maintainer of Source to Hub project which loads data directly from source into google bigquery. Project mainly aimed',\n",
       "   'Pune, Maharashtra, India',\n",
       "   'July 2018 - Present',\n",
       "   'at eliminating intermediate data loading in native hadoop clusters for more efficiency, reliability and speed',\n",
       "   '• Responsible for implementing and managing an end-to-end CI/CD Pipelines with custom validations for Informatica migrations',\n",
       "   'which brought migration time to 1.5 hours from 9 hours without any manual intervention',\n",
       "   '• Enhancing, auditing and maintaining custom data ingestion framework that ingest around 1TB of data each day to over 70 business',\n",
       "   'units',\n",
       "   '• Working with L3 developer team to ensure the discussed Scrum PBI’s are delivered on time for data ingestions',\n",
       "   '• Planning and Executing QA and Production Release Cycle activities',\n",
       "   'Truso',\n",
       "   'FULL STACK DEVELOPER INTERN',\n",
       "   '• Created RESTful APIs using Django REST Framework',\n",
       "   '• Created event based fully dynamic frontend using Angular 5/6',\n",
       "   '• Developed and managed MySQL databases and RDBMS architecture',\n",
       "   'Pune, Maharashtra, India',\n",
       "   'June 2018 - July 2018',\n",
       "   'Propeluss',\n",
       "   'DATA ENGINEERING INTERN',\n",
       "   'October 2017 - January 2018',\n",
       "   '• Wrote various automation scripts to scrape data from various websites that were managed by messaging queue using Celery',\n",
       "   'Pune, Maharashtra, India',\n",
       "   'pipelines and RabbitMQ',\n",
       "   '• Applied Natural Language Processing to articles scraped from the internet to extract different entities in these articles using entity',\n",
       "   'extraction algorithms and applying Machine Learning algorithms like Naive Bayes to classify these articles',\n",
       "   '• Applied KNN with LSA for extracting relevant tags for various startups based on their works',\n",
       "   '• A simple resume parser used for extracting information from resumes',\n",
       "   '• Extract information from thousands of resumes in just a few seconds',\n",
       "   '• Author and maintainer of this project',\n",
       "   '• 15k+ downloads on Github',\n",
       "   '• Author and maintainer of this project',\n",
       "   '• An educational library to teach all the major algorithms',\n",
       "   '• Got covered in Fosstack, FullStackFeed, Kleiber and Tagged under Hotest Github Project on ITCodeMonkey',\n",
       "   '• 20k+ downloads on Github',\n",
       "   'API/Python Package',\n",
       "   'July 2019 - Present',\n",
       "   'API / Python Package',\n",
       "   'July 2017 - Present'],\n",
       "  'company_names': None,\n",
       "  'no_of_pages': 2,\n",
       "  'total_experience': 10.58}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_remote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e25d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --user spacy==2.3.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c569d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gzNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from en-core-web-sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.59.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.0.6)\n",
      "\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en-core-web-sm==2.3.1) (2.10)\n"
     ]
    }
   ],
   "source": [
    "#pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dec10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyresparser in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.6)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2.10)\n",
      "Requirement already satisfied: blis>=0.2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.16.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (1.20.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (1.2.4)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (4.59.0)\n",
      "Requirement already satisfied: nltk>=3.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (3.6.1)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (3.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (1.15.0)\n",
      "Requirement already satisfied: thinc>=7.0.4 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from pyresparser) (7.4.5)\n",
      "Requirement already satisfied: pytz>=2019.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2021.1)\n",
      "Requirement already satisfied: preshed>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (3.0.6)\n",
      "Requirement already satisfied: pyrsistent>=0.15.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (0.17.3)\n",
      "Requirement already satisfied: srsly>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (1.0.5)\n",
      "Requirement already satisfied: chardet>=3.0.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (4.0.0)\n",
      "Requirement already satisfied: wasabi>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (0.8.2)\n",
      "\n",
      "Requirement already satisfied: cymem>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2.0.6)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from pyresparser) (19.1.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2.25.1)\n",
      "Requirement already satisfied: spacy>=2.1.4 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from pyresparser) (2.3.5)\n",
      "Requirement already satisfied: certifi>=2019.6.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2.8.1)\n",
      "Requirement already satisfied: pdfminer.six>=20181108 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (20211012)\n",
      "Requirement already satisfied: sortedcontainers>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (2.3.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (3.11.0)\n",
      "Requirement already satisfied: docx2txt>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (0.8)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyresparser) (1.26.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema>=3.0.1->pyresparser) (52.0.0.post20210125)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (2021.4.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.4.3->pyresparser) (7.1.2)\n",
      "Requirement already satisfied: cryptography in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer.six>=20181108->pyresparser) (3.4.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from preshed>=2.0.1->pyresparser) (1.0.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from spacy>=2.1.4->pyresparser) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\mmazhar\\appdata\\roaming\\python\\python38\\site-packages (from spacy>=2.1.4->pyresparser) (1.1.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography->pdfminer.six>=20181108->pyresparser) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->pdfminer.six>=20181108->pyresparser) (2.20)\n"
     ]
    }
   ],
   "source": [
    "#pip install pyresparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb307306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_data():\n",
    "    data = ResumeParser('Muhammad-CV (1).pdf').get_extracted_data()\n",
    "    return data\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ede479c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Muhammad Mazhar',\n",
       " 'email': 'm.mazharwattoo@gmail.com',\n",
       " 'mobile_number': '343.0012556',\n",
       " 'skills': ['Database',\n",
       "  'Xml',\n",
       "  'Reports',\n",
       "  'Website',\n",
       "  'International',\n",
       "  'Billing',\n",
       "  'Security',\n",
       "  'Certification',\n",
       "  'Intranet',\n",
       "  'Test plans',\n",
       "  'Html',\n",
       "  'Css',\n",
       "  'Mathematics',\n",
       "  'Sql server',\n",
       "  'Sharepoint',\n",
       "  'Process',\n",
       "  'System',\n",
       "  'English',\n",
       "  'Engineering',\n",
       "  'Pandas',\n",
       "  'Machine learning',\n",
       "  'C',\n",
       "  'Api',\n",
       "  'Client service',\n",
       "  'Investigate',\n",
       "  'Marketing',\n",
       "  'Design',\n",
       "  'Email',\n",
       "  'Technical',\n",
       "  'Analysis',\n",
       "  'Training',\n",
       "  'Reporting',\n",
       "  '.net',\n",
       "  'Linux',\n",
       "  'Programming',\n",
       "  'Improvement',\n",
       "  'Distribution',\n",
       "  'Automation',\n",
       "  'Python',\n",
       "  'Javascript',\n",
       "  'Research',\n",
       "  'Legal',\n",
       "  'Github',\n",
       "  'Html5',\n",
       "  'Specifications',\n",
       "  'Mining',\n",
       "  'Compliance',\n",
       "  'Inventory',\n",
       "  'Accounting',\n",
       "  'Architecture',\n",
       "  'Writing',\n",
       "  'Sql',\n",
       "  'Plan'],\n",
       " 'college_name': None,\n",
       " 'degree': ['Diploma', 'Bachelors in Science , BS Computer Science'],\n",
       " 'designation': ['ASP.NET Developer',\n",
       "  'Application Development',\n",
       "  'Software Engineer',\n",
       "  'Machine Learning'],\n",
       " 'experience': ['Jul 2019 - Present',\n",
       "  'Software Engineer',\n",
       "  'Ghost Digital & Data (GD&D), Lahore, Pakistan',\n",
       "  'Participate in requirements analysis',\n",
       "  'Collaborate with internal teams to produce software design and architecture',\n",
       "  'Write clean, scalable code using .NET programming languages',\n",
       "  'Test and deploy applications and systems',\n",
       "  'Revise, update, refactor and debug code',\n",
       "  'Improve existing software',\n",
       "  'Serve as an expert on applications and provide technical support',\n",
       "  'Nov 2019 - Dec 2020',\n",
       "  'Software Engineer',\n",
       "  'Animal Quarantine Department Lahore, Govt of Pakistan, Lahore, Pakistan',\n",
       "  '\"The Animal Quarantine Department (AQD) is an attached department of Ministry of',\n",
       "  'National Food Security & Research.',\n",
       "  'AQD provide’s quarantine, inspection and certification services at seven different',\n",
       "  'locations across Pakistan\".',\n",
       "  'AQD is my client . I am develping an window based application for managing their',\n",
       "  'Import & Export certificates and intenal document management system.',\n",
       "  'Jan 2019 - Jun 2019',\n",
       "  'ASP.NET Developer',\n",
       "  'Originator IT Solution, Lahore, Pakistan',\n",
       "  'Utilize established development tools, guidelines and conventions including but',\n",
       "  'not limited to ASP.NET, SQL Server, HTML, CSS, JavaScript, and C#/VB.NET',\n",
       "  'Prepare and maintain code for various .Net applications and resolve any defects',\n",
       "  'in systems.',\n",
       "  'Prepare test based applications for various .Net applications.',\n",
       "  'Enhance existing systems by analyzing business objectives,',\n",
       "  'preparing an action plan and identifying areas for modification and improvement',\n",
       "  'Page 1 of 4',\n",
       "  'Manage defect tracking system and resolve all issues and prepare update for'],\n",
       " 'company_names': ['Microsoft', 'EmanZara'],\n",
       " 'no_of_pages': 4,\n",
       " 'total_experience': 3.92}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_local_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cd8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_remote_name():\n",
    "    data = get_remote_data()\n",
    "    assert 'Omkar Pathak' == data[0]['name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f7eea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from: https://www.omkarpathak.in/downloads/OmkarResume.pdf\n",
      "<pyresparser.resume_parser.ResumeParser object at 0x0000011BFA170310>\n"
     ]
    }
   ],
   "source": [
    "test_remote_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24561088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_remote_phone_number():\n",
    "    data = get_remote_data()\n",
    "    assert '8087996634' == data[0]['mobile_number']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265a1df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from: https://www.omkarpathak.in/downloads/OmkarResume.pdf\n",
      "<pyresparser.resume_parser.ResumeParser object at 0x0000011B88CE75B0>\n"
     ]
    }
   ],
   "source": [
    "test_remote_phone_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8642ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_local_name():\n",
    "    data = get_local_data()\n",
    "    assert 'Omkar Pathak' == data['name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452dae81",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a2ff7077295b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_local_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-8f63d82a55fd>\u001b[0m in \u001b[0;36mtest_local_name\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_local_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_local_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;34m'Omkar Pathak'\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_local_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b5c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local_phone_number():\n",
    "    data = get_local_data()\n",
    "    assert '8087996634' == data['mobile_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4d29ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-caf97d403ce4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_local_phone_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-5ad2434cc2a0>\u001b[0m in \u001b[0;36mtest_local_phone_number\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtest_local_phone_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_local_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;34m'8087996634'\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mobile_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_local_phone_number()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
